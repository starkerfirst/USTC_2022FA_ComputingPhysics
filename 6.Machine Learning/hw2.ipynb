{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练在Nvidia GPU平台上进行，运行使用py文件，输出放在output.txt文件内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "步骤一：数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SUSY_Dataset(Dataset):\n",
    "    def __init__(self, train_size, train):\n",
    "\n",
    "        self.features=['SUSY','lepton 1 pT', 'lepton 1 eta', 'lepton 1 phi', 'lepton 2 pT', 'lepton 2 eta', 'lepton 2 phi', \n",
    "                'missing energy magnitude', 'missing energy phi', 'MET_rel', 'axial MET', 'M_R', 'M_TR_2', 'R', 'MT2', \n",
    "                'S_R', 'M_Delta_R', 'dPhi_r_b', 'cos(theta_r1)']\n",
    "        #Number of datapoints to work with\n",
    "        self.df = pd.read_csv(\"SUSY\", header=None,nrows=5000000,engine='python')\n",
    "        self.df.columns=self.features\n",
    "        Y = self.df['SUSY']\n",
    "        X = self.df[[col for col in self.df.columns if col!=\"SUSY\"]]\n",
    "\n",
    "        print(f\"total sample: {len(Y)}\")\n",
    "\n",
    "        # set training and test data size\n",
    "        if train==True:\n",
    "            X=X[:train_size]\n",
    "            Y=Y[:train_size]\n",
    "            print(\"Training on {} examples\".format(train_size))\n",
    "        else:\n",
    "            X=X[5000000-train_size:]\n",
    "            Y=Y[5000000-train_size:]\n",
    "            print(\"Testing on {} examples\".format(train_size))\n",
    "       \n",
    "        self.data=(X.values.astype(np.float32),Y.values.astype(int))\n",
    "        print(\"Using both high and low level features\")\n",
    "        print(f\"num_samples: {len(self.data[1])}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data[1])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample=(self.data[0][idx],self.data[1][idx])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "步骤二：建立网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, hidden_neuron, hidden_layer_num):\n",
    "        # inherit attributes and methods of nn.Module\n",
    "        super(model, self).__init__()\n",
    "        self.hidden_neuron = hidden_neuron\n",
    "        self.hidden_layer_num = hidden_layer_num\n",
    "\n",
    "        self.fc = []\n",
    "        self.fc.append(nn.Linear(18, hidden_neuron))\n",
    "        for i in range(hidden_layer_num-1):\n",
    "            self.fc.append(nn.Linear(hidden_neuron, hidden_neuron))\n",
    "        self.fc.append(nn.Linear(hidden_neuron, 2))\n",
    "        self.fc.append(nn.Sigmoid())\n",
    "        self.layers = nn.ModuleList(self.fc) \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc[0](x)\n",
    "        for i in range(self.hidden_layer_num-1):\n",
    "            x = self.fc[i+1](x)\n",
    "        x = self.fc[len(self.fc)-2](x)  \n",
    "        x = self.fc[len(self.fc)-1](x) \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "步骤三：定义损失函数与优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(epochs, hidden_neuron, hidden_layer_num, train_loader, test_loader,learning_rate):\n",
    "\n",
    "    DNN = model(hidden_neuron, hidden_layer_num)\n",
    "    # 初始化参数\n",
    "    for layer in DNN.layers:\n",
    "        if type(layer) == nn.Linear:\n",
    "            layer.weight.data.normal_(0, 0.1)\n",
    "            layer.bias.data.fill_(0)\n",
    "    DNN = DNN.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion = criterion.to(device)\n",
    "    optimizer = torch.optim.SGD(DNN.parameters(), lr=learning_rate)\n",
    "    \n",
    "    \n",
    "    def train(epochs,optimizer,criterion,train_loader,test_loader):\n",
    "        DNN_cuda = nn.DataParallel(DNN, device_ids=[0,1,2,3])\n",
    "        criterion = nn.DataParallel(criterion, device_ids=[0,1,2,3])\n",
    "        optimizer = nn.DataParallel(optimizer, device_ids=[0,1,2,3])\n",
    "        for batch_idx, (data, label) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = DNN_cuda.module(data).to(device)\n",
    "            loss = criterion.module(output, label).to(device)\n",
    "            loss.backward()\n",
    "            optimizer.module.step()\n",
    "            \n",
    "            # print loss at current epoch\n",
    "            if batch_idx % 5 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item() ))\n",
    "            \n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def test(optimizer,criterion,train_loader,test_loader):\n",
    "        test_loss = 0 # loss function on test data\n",
    "        correct = 0 # number of correct predictions\n",
    "        DNN_cuda = nn.DataParallel(DNN, device_ids=[0,1,2,3])\n",
    "        criterion = nn.DataParallel(criterion, device_ids=[0,1,2,3])\n",
    "        optimizer = nn.DataParallel(optimizer, device_ids=[0,1,2,3])\n",
    "        # loop over test data\n",
    "        for data, label in test_loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            # compute model prediction softmax probability\n",
    "            \n",
    "            output = DNN_cuda.module(data).to(device)\n",
    "            # compute test loss\n",
    "            test_loss += criterion.module(output, label).to(device).item() # sum up batch loss\n",
    "            # find most likely prediction\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            # update number of correct predictions\n",
    "            correct += pred.eq(label.data.view_as(pred)).sum().item()\n",
    "\n",
    "        # print test loss\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        \n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "        \n",
    "\n",
    "        return test_loss, correct / len(test_loader.dataset)\n",
    "\n",
    "    train_loss=np.zeros(epochs)\n",
    "    test_loss=np.zeros_like(train_loss)\n",
    "    test_accuracy=np.zeros_like(train_loss)\n",
    "\n",
    "    epochs=range(1, epochs + 1)\n",
    "    for epoch in epochs:\n",
    "        train_loss[epoch-1] = train(epoch,optimizer,criterion,train_loader,test_loader)\n",
    "        test_loss[epoch-1], test_accuracy[epoch-1] = test(optimizer,criterion,train_loader,test_loader)\n",
    "\n",
    "    return test_accuracy[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "步骤四：调用函数完成实验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用单层隐藏神经元 1000 个，研究预言正确率与训练样本大小的关系，训练样本数目范围1000->4500000，画出关系图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = np.linspace(1000, 4500000, 10).astype(int)\n",
    "correctness = []\n",
    "testset = SUSY_Dataset(500000, False)\n",
    "test_loader = DataLoader(\n",
    "        testset,\n",
    "        batch_size=64, shuffle=True)\n",
    "\n",
    "for size in train_size:\n",
    "    trainset = SUSY_Dataset(size, True)\n",
    "    train_loader = DataLoader(\n",
    "        trainset,\n",
    "        batch_size=1000, shuffle=True)\n",
    "    \n",
    "    correctness.append(evaluate_model(30, 1000, 1, train_loader, test_loader,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10), dpi=100)\n",
    "plt.plot(train_size, correctness,'-bo')\n",
    "plt.xlabel(\"hiddenlayer_num\")\n",
    "plt.ylabel(\"correctness\")\n",
    "plt.savefig(\"pic1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "固定隐藏层神经元每层100个，研究正确率与隐藏层数的关系，层数范围1-5，画出关系图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddenlayer_num = range(1,6)\n",
    "correctness = []\n",
    "trainset = SUSY_Dataset(4500000, True)\n",
    "testset = SUSY_Dataset(500000, False)\n",
    "train_loader = DataLoader(\n",
    "        trainset,\n",
    "        batch_size=64, shuffle=True)\n",
    "    \n",
    "test_loader = DataLoader(\n",
    "        testset,\n",
    "        batch_size=1000, shuffle=False)\n",
    "\n",
    "for num in hiddenlayer_num:\n",
    "    correctness.append(evaluate_model(10, 100, num, train_loader, test_loader,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5), dpi=100)\n",
    "plt.plot(hiddenlayer_num, correctness,'-bo')\n",
    "plt.xlabel(\"hiddenlayer_num\")\n",
    "plt.ylabel(\"correctness\")\n",
    "plt.savefig(\"pic2.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ybh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04b2af5065e72674440178c5fc3ac0765a3a2b3930a9d7a3b64fd52b1d058f7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
